Задача проекта: понять и научиться, как правильно проводить подготовку данных, анализировать особенности, выявлять закономерности в них для последующего использования.

Данные бывают разные, по разному заполнены, загрязнены шумом и ненужной информацией. Информация может быть как числовая так и текстовая, что необходимо учитывать.

Я выделил бы 6 этапов: предварительная обработка, анализ признаков, корреляционный анализ, анализ номинативных данных, обработка (хотя данный пункт почти во всех других встречается) данных и выводы.

Ответы на вопросы саморефлексии:
  1)  Какова была ваша роль в команде?

    1.1) Делал самостоятельно.

  2) Какой частью своей работы вы остались особенно довольны?

    2.1) Научился рисовать красивые графики и использовать теорию на практике.

    2.2) Не забыл чему учили раньше.

    2.3) Научился работать с Numpy.

  3) Что не получилось сделать так, как хотелось? Над чем ещё стоит поработать?

    3.1) Не получилось установить autopep8.

    3.2) Непонятно, как заполнить пропуски, мыслей много, а где она та самая?..

    3.3) Не удалось убрать предупреждения вида: FutureWarning: Pass the following variable as a keyword arg: x. ... Наверное, плохо искал :(

  4) Что интересного и полезного вы узнали в этом модуле?

    4.1) Я повторил ТВИМС и применил его на практике.

    4.2) Numpy.

    4.3) Оказывается здоровье и прогулы не влияют на учёбу:)

  5) Что является вашим главным результатом при прохождении этого проекта?

    5.1) Я вспомнил ТВИМС и нашёл, где это можно применять в жизни.

    5.2) Научился (надеюсь) в Python проводить разведовательный анализ данных.

  6) Какие навыки вы уже можете применить в текущей деятельности?

    6.1) Работа с Numpy.

    6.2) Лучше понимаю 2 главу из книги О. Жерона и могу объяснить что к чему.

  7) Планируете ли вы дополнительно изучать материалы по теме проекта?

    7.1) Безусловно Numpy и материлы по ML.

Спасибо за Внимание!
